from pyspark.ml.regression import RandomForestRegressor
import numpy as np

rf = RandomForestRegressor(labelCol="likes", featuresCol="features")

pipeline_rf = Pipeline(stages=[vecAssembler, rf])
cvModel_rf = pipeline_rf.fit(trainDelta)

predictions = cvModel_rf.transform(testDelta)
display(predictions.select("features", "likes", "prediction").orderBy("likes", ascending=False).limit(5))

evaluator = RegressionEvaluator(labelCol="likes", predictionCol="prediction", metricName="rmse")
rmse = evaluator.evaluate(predictions)

rfPred = cvModel_rf.transform(df_base4)
rfResult = rfPred.toPandas()
rf_resi = rfResult.likes - rfResult.prediction

plt.plot(rfResult.likes, rf_resi, 'bo')
plt.xlabel('likes')
plt.ylabel('Residual')
plt.suptitle("Residual Model with Performance RMSE: %f" % rmse)
plt.show()

r2 = evaluator.setMetricName("r2").evaluate(predictions)
print(f"RMSE is {rmse}")
print(f"R2 is {r2}")


######HYPERparameter Tuning for Random Forest#########
rf = RandomForestRegressor(labelCol="likes", featuresCol="features")
evaluator = RegressionEvaluator(labelCol="likes", predictionCol="prediction")

# set the paraGrid with numTrees=[10, 20, 50], maxDepth=[5, 10, 15]. 
paramGrid_rf = (ParamGridBuilder()
            .addGrid(rf.numTrees, [10, 20, 50])
            .addGrid(rf.maxDepth, [5, 10, 15])
            .build())

# apply cross validation with numFolds=2, parallelism=2.
cv_rf = CrossValidator(estimator=rf, evaluator=evaluator, estimatorParamMaps=paramGrid_rf, 
                    numFolds=2, parallelism=2, seed=345)

stagesWithCV_rf = [vecAssembler, cv_rf]
pipeline_cvrf = Pipeline(stages=stagesWithCV_rf)

# fir the model again with pipeline
pipelineModel_cvrf = pipeline_cvrf.fit(trainDelta)

predDF_cvrf = pipelineModel_cvrf.transform(testDelta)

rmse = evaluator.evaluate(predDF_cvrf)
r2 = evaluator.setMetricName("r2").evaluate(predDF_cvrf)
print(f"RMSE is {rmse}")
print(f"R2 is {r2}")
